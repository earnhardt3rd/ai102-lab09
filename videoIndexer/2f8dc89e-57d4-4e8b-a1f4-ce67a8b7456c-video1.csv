0.8955763578414917,00:00:01.750,00:00:04.886,SPEAKER 1: We believe in the potential of AI to improve our
0.8955763578414917,00:00:04.951,00:00:07.891,SPEAKER 1: lives and big and small ways. We need to make
0.8955763578414917,00:00:07.957,00:00:10.440,SPEAKER 1: sure it's for the benefit of everyone.
0.8955763578414917,00:00:10.950,00:00:14.464,"SPEAKER 2: For the first time, we're having machines moved into roles"
0.8955763578414917,00:00:14.525,00:00:17.736,SPEAKER 2: that have been the roles of human beings. Might these
0.8955763578414917,00:00:17.797,00:00:21.917,SPEAKER 2: technologies have inadvertent effects on people and society? Do they
0.8955763578414917,00:00:21.978,00:00:25.311,"SPEAKER 2: align with people's values, their ethics? We need it to"
0.8955763578414917,00:00:25.371,00:00:28.220,SPEAKER 2: think through the implications for our company.
0.8955763578414917,00:00:28.950,00:00:30.800,SPEAKER 1: Responsible AI is the.
0.8350234627723694,00:00:30.890,00:00:35.398,"SPEAKER 1: Approach that we take to developing and deploying our technology,"
0.8350234627723694,00:00:35.467,00:00:39.281,SPEAKER 1: making sure our principles are brought to life and that
0.8350234627723694,00:00:39.351,00:00:43.790,SPEAKER 1: it empowers everyone and is inclusive and accessible for people.
0.8350234627723694,00:00:43.900,00:00:44.510,SPEAKER 2: Apple.
0.8350234627723694,00:00:44.620,00:00:47.920,"SPEAKER 1: Excellent, the job of the Office of responsible AI is"
0.8350234627723694,00:00:47.983,00:00:52.280,SPEAKER 1: to put our principles into practice by operationalising ethics across
0.8350234627723694,00:00:52.342,00:00:53.090,SPEAKER 1: the company.
0.8350234627723694,00:00:53.170,00:00:56.846,SPEAKER 2: The Ethics Committee is responsible for deliberating about hard new
0.8350234627723694,00:00:56.901,00:00:57.450,SPEAKER 2: questions.
0.8350234627723694,00:00:57.460,00:00:59.810,SPEAKER 1: We are sister organizations.
0.8917409181594849,00:01:00.890,00:01:04.068,SPEAKER 2: We have to think through what it means to detect
0.8917409181594849,00:01:04.135,00:01:07.711,"SPEAKER 2: bias, make our systems more fair, to detect errors and"
0.8917409181594849,00:01:07.777,00:01:11.751,"SPEAKER 2: blind spots in our technologies, and on thinking through the"
0.8917409181594849,00:01:11.817,00:01:15.261,SPEAKER 2: kinds of advice we give to other organizations on to
0.8917409181594849,00:01:15.327,00:01:19.301,SPEAKER 2: our leaders where technology can impose on privacy and human
0.8917409181594849,00:01:19.367,00:01:23.870,SPEAKER 2: rights. Responsibility is at the core world. Learning everyday about
0.8917409181594849,00:01:23.937,00:01:26.520,SPEAKER 2: this new role of responsible computing.
0.8917409181594849,00:01:26.690,00:01:30.950,SPEAKER 1: We need to translate academic thought to language that.
0.8749055862426758,00:01:31.069,00:01:35.698,"SPEAKER 1: Engineers and salespeople are familiar with our customers, have grappling"
0.8749055862426758,00:01:35.761,00:01:38.931,SPEAKER 1: with many of the same issues. It's incumbent on us
0.8749055862426758,00:01:38.995,00:01:40.580,SPEAKER 1: to share what we learned.
0.8749055862426758,00:01:41.110,00:01:44.095,SPEAKER 2: It's about trying to do better everyday working with our
0.8749055862426758,00:01:44.148,00:01:48.147,SPEAKER 2: customers and outside agencies to develop processes and deliver responsible
0.8749055862426758,00:01:48.200,00:01:50.119,SPEAKER 2: computing technologies to the world.
