1
00:00:01,750 --> 00:00:04,886
SPEAKER 1: We believe in the potential of AI to improve our

2
00:00:04,951 --> 00:00:07,891
SPEAKER 1: lives and big and small ways. We need to make

3
00:00:07,957 --> 00:00:10,440
SPEAKER 1: sure it's for the benefit of everyone.

4
00:00:10,950 --> 00:00:14,464
SPEAKER 2: For the first time, we're having machines moved into roles

5
00:00:14,525 --> 00:00:17,736
SPEAKER 2: that have been the roles of human beings. Might these

6
00:00:17,797 --> 00:00:21,917
SPEAKER 2: technologies have inadvertent effects on people and society? Do they

7
00:00:21,978 --> 00:00:25,311
SPEAKER 2: align with people's values, their ethics? We need it to

8
00:00:25,371 --> 00:00:28,220
SPEAKER 2: think through the implications for our company.

9
00:00:28,950 --> 00:00:30,800
SPEAKER 1: Responsible AI is the.

10
00:00:30,890 --> 00:00:35,398
SPEAKER 1: Approach that we take to developing and deploying our technology,

11
00:00:35,467 --> 00:00:39,281
SPEAKER 1: making sure our principles are brought to life and that

12
00:00:39,351 --> 00:00:43,790
SPEAKER 1: it empowers everyone and is inclusive and accessible for people.

13
00:00:43,900 --> 00:00:44,510
SPEAKER 2: Apple.

14
00:00:44,620 --> 00:00:47,920
SPEAKER 1: Excellent, the job of the Office of responsible AI is

15
00:00:47,983 --> 00:00:52,280
SPEAKER 1: to put our principles into practice by operationalising ethics across

16
00:00:52,342 --> 00:00:53,090
SPEAKER 1: the company.

17
00:00:53,170 --> 00:00:56,846
SPEAKER 2: The Ethics Committee is responsible for deliberating about hard new

18
00:00:56,901 --> 00:00:57,450
SPEAKER 2: questions.

19
00:00:57,460 --> 00:00:59,810
SPEAKER 1: We are sister organizations.

20
00:01:00,890 --> 00:01:04,068
SPEAKER 2: We have to think through what it means to detect

21
00:01:04,135 --> 00:01:07,711
SPEAKER 2: bias, make our systems more fair, to detect errors and

22
00:01:07,777 --> 00:01:11,751
SPEAKER 2: blind spots in our technologies, and on thinking through the

23
00:01:11,817 --> 00:01:15,261
SPEAKER 2: kinds of advice we give to other organizations on to

24
00:01:15,327 --> 00:01:19,301
SPEAKER 2: our leaders where technology can impose on privacy and human

25
00:01:19,367 --> 00:01:23,870
SPEAKER 2: rights. Responsibility is at the core world. Learning everyday about

26
00:01:23,937 --> 00:01:26,520
SPEAKER 2: this new role of responsible computing.

27
00:01:26,690 --> 00:01:30,950
SPEAKER 1: We need to translate academic thought to language that.

28
00:01:31,069 --> 00:01:35,698
SPEAKER 1: Engineers and salespeople are familiar with our customers, have grappling

29
00:01:35,761 --> 00:01:38,931
SPEAKER 1: with many of the same issues. It's incumbent on us

30
00:01:38,995 --> 00:01:40,580
SPEAKER 1: to share what we learned.

31
00:01:41,110 --> 00:01:44,095
SPEAKER 2: It's about trying to do better everyday working with our

32
00:01:44,148 --> 00:01:48,147
SPEAKER 2: customers and outside agencies to develop processes and deliver responsible

33
00:01:48,200 --> 00:01:50,119
SPEAKER 2: computing technologies to the world.