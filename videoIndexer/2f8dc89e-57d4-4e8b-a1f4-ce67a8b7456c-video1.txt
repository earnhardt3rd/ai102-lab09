SPEAKER 1: We believe in the potential of AI to improve our
SPEAKER 1: lives and big and small ways. We need to make
SPEAKER 1: sure it's for the benefit of everyone.
SPEAKER 2: For the first time, we're having machines moved into roles
SPEAKER 2: that have been the roles of human beings. Might these
SPEAKER 2: technologies have inadvertent effects on people and society? Do they
SPEAKER 2: align with people's values, their ethics? We need it to
SPEAKER 2: think through the implications for our company.
SPEAKER 1: Responsible AI is the.
SPEAKER 1: Approach that we take to developing and deploying our technology,
SPEAKER 1: making sure our principles are brought to life and that
SPEAKER 1: it empowers everyone and is inclusive and accessible for people.
SPEAKER 2: Apple.
SPEAKER 1: Excellent, the job of the Office of responsible AI is
SPEAKER 1: to put our principles into practice by operationalising ethics across
SPEAKER 1: the company.
SPEAKER 2: The Ethics Committee is responsible for deliberating about hard new
SPEAKER 2: questions.
SPEAKER 1: We are sister organizations.
SPEAKER 2: We have to think through what it means to detect
SPEAKER 2: bias, make our systems more fair, to detect errors and
SPEAKER 2: blind spots in our technologies, and on thinking through the
SPEAKER 2: kinds of advice we give to other organizations on to
SPEAKER 2: our leaders where technology can impose on privacy and human
SPEAKER 2: rights. Responsibility is at the core world. Learning everyday about
SPEAKER 2: this new role of responsible computing.
SPEAKER 1: We need to translate academic thought to language that.
SPEAKER 1: Engineers and salespeople are familiar with our customers, have grappling
SPEAKER 1: with many of the same issues. It's incumbent on us
SPEAKER 1: to share what we learned.
SPEAKER 2: It's about trying to do better everyday working with our
SPEAKER 2: customers and outside agencies to develop processes and deliver responsible
SPEAKER 2: computing technologies to the world.